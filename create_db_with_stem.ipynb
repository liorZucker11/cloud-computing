{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEQdMQEWntf7M/6D5+yqc0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liorZucker11/cloud-computing/blob/main/create_db_with_stem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "def fetch_page_and_sublinks(url, max_sublinks=50):\n",
        "    results = {}\n",
        "    visited_urls = set()\n",
        "\n",
        "    def fetch(url):\n",
        "        if len(visited_urls) >= max_sublinks:\n",
        "            return\n",
        "        if url[-1] != \"/\":\n",
        "          url += \"/\"\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            results[url] = soup\n",
        "            visited_urls.add(url)\n",
        "            # Find all links in the soup object\n",
        "            for link in soup.find_all('a', href=True):\n",
        "              suffix = link.get('href')\n",
        "              if suffix == \"#main\":\n",
        "                suffix = \"\"\n",
        "              full_url = urljoin(url, suffix)\n",
        "              if \"azure\" not in full_url:\n",
        "                continue\n",
        "              if full_url not in visited_urls:\n",
        "                  fetch(full_url)  # Recursively fetch sublinks\n",
        "                  if len(visited_urls) >= max_sublinks:\n",
        "                    return\n",
        "        else:\n",
        "            results[url] = None\n",
        "\n",
        "    fetch(url)\n",
        "    return results"
      ],
      "metadata": {
        "id": "wKaKPzKxtBox"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "url = \"https://azure.microsoft.com/en-us\"  # Replace with the URL you want to fetch\n",
        "data = fetch_page_and_sublinks(url)\n",
        "print(data.keys())  # This will print the URLs of the main page and sublinks fetched"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFFKQvb57jyX",
        "outputId": "5adf7f6f-c95e-445a-9992-2928ccdb31bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['https://azure.microsoft.com/en-us/', 'https://portal.azure.com/', 'https://azure.microsoft.com/en-us/free/'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = {'a', 'an', 'the','I', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\n",
        " 'in', 'to', 'for', 'with', 'on', 'at', 'by', 'from', 'up', 'off', 'about', 'into', 'over', 'after',\n",
        " 'and', 'but', 'or', 'as', 'if', 'when', 'than', 'because', 'while', 'where','be', 'have', 'do', 'is', 'am', 'are', 'was', 'were', 'being', 'been',\n",
        " 'some', 'such', 'only', 'own', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'}"
      ],
      "metadata": {
        "id": "qlthCFq-6zC_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def index_words(index, html_link, soup,stemmer):\n",
        "  words = re.findall(r'\\w+', soup.get_text())\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    word = stemmer.stem(word)\n",
        "    if word in stop_words:\n",
        "      continue\n",
        "    if word in index:\n",
        "      index[word][\"count\"] += 1\n",
        "      if html_link in index[word][\"links\"]:\n",
        "        index[word][\"links\"][html_link] += 1\n",
        "      else:\n",
        "        index[word][\"links\"][html_link] = 1\n",
        "    else:\n",
        "      index[word] = {\"count\": 1, \"links\": {html_link:1}}\n",
        "  return index"
      ],
      "metadata": {
        "id": "9nHSewtBZyfF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "def create_index(url):\n",
        "  stemmer = PorterStemmer()\n",
        "  dic = fetch_page_and_sublinks(url)\n",
        "  index = {}\n",
        "  for html_link in dic:\n",
        "    html_data = dic[html_link]\n",
        "    index = index_words(index, html_link ,html_data,stemmer)\n",
        "  #index = apply_stemming(index)\n",
        "  return index\n"
      ],
      "metadata": {
        "id": "yS5naD91b2y1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://azure.microsoft.com/en-us'\n",
        "index = create_index(url)\n",
        "#print(index)\n",
        "#print(index['bird'])\n",
        "#print(index['john'])"
      ],
      "metadata": {
        "id": "Idvh1JNBcWdL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# The file path where you want to save the JSON data\n",
        "file_path = 'my_data.json'\n",
        "\n",
        "# Writing the dictionary to a file as JSON\n",
        "with open(file_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(index, f, ensure_ascii=False, indent=4)\n"
      ],
      "metadata": {
        "id": "0yUIV52k5fyY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(index['elected'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlyjN4pxwyYc",
        "outputId": "644dd0bf-cb51-467a-ff82-40fb12b43741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'count': 1, 'links': {'https://en.wikipedia.org/wiki/Main_Page': 1}}\n"
          ]
        }
      ]
    }
  ]
}